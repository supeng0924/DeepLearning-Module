# Deep Learning summary
[toc]



### 1. 卷积

```
1.概念：卷积核和感受野中的元素相乘后求和的结果，并滑动完整个图像的过程
2.作用：
	1) 提取图像的特征，并且卷积核权重可学习，能突破传统滤波器的限制，根据目标函数学习出想要的特征
	2) “局部感知，参数共享”，大大降低了参数量，保证网络的稀疏性，防止过拟合
3.小卷积核相对于大卷积核的优势：
	1) 增加了网络容量和模型复杂度：小卷积核的多层叠加，加深了网络的深度
	2) 减少了参数量，例如
4.1x1卷积核作用
	1) 可以升维和降维
	2) 可以实现跨通道信息交互和融合
	3) 以较少的参数量加宽加深网络的层数，加入更多的非线性
```

### 2. 池化

```
1.概念：将图像缩小，减少像素信息，只保留重要的信息，主要为了减少参数量
2.作用：
	1) 特征不变性：汇合操作更关注某些特征而不是具体位置，所以能容忍一些微小的偏移
	2) 特征降维：汇合结果中的一个元素对应原始输入数据的一个子区域，相当于在范围空间做了维度的约减
	3) 一定程度上可以防止过拟合
```

### 3. BN

```
1.深度神经网络难训练的原因：
	1) 层与层之间存在高度关联性和耦合性，会导致底层参数微弱变化，由于每层的线性变换与非线性激活，随着网络层数加深而被放大。
	2) 内部协变量偏移(internal covariate shift)。参数的变化导致每一层的输入分布会发生改变，进而上层的网络需要不停地去适应这些分布的变化，使得模型训练变得困难，

2.BN内部原理： 通过正则化手段，在数据进入激活函数之前，强迫数据保持均值为0，方差为1的的正态分布，避免梯度消失。例如对于sigmoid而言，把逐渐向非线性饱和区靠拢的输入强制拉回到均值为0，方差为1标准正态分布，使得非线性输入落入到比较敏感的区域，以此避免梯度消失。同时为了防止网络表达能力下降，引入缩放和平移参数，通过训练来学习，使得表达能力增强。

3.好处：
	1) 调参过程变简单，对初始化要求没那么高，可以使用大学习率
	2) 降低了数据间的绝对差异，更多的考虑相对差异性
	3) 本身是一种正则化
```

BN的计算过程：

1.对mini-batch 求均值   $\mu_{B}=\frac{1}{m}\sum_{i=1}^mx_i$        

2.对mini-batch求方差 $\sigma_B^2=\frac{1}{m}\sum_{i=1}^m(x_i-\mu_B) $   

3.标准化数据 $\widehat{x_i}=\frac{(x_i-\mu_B)^2}{\sqrt{\sigma_B^2+\epsilon}}$   

4.缩放和平移 $y=\nu\widehat{x_i}+\beta$  

```
BN(batch normalization)是在batch上对N,H,W三个维度做归一化，保留C的维度。适用于固定深度的前向神经网络，如CNN
LN(layer normalization)是在通道上对C，H，W做归一化
IN(instance normalization)对H，W做归一化
GN(group normalization)，对每个group(C/G),H,W做归一化，适用于占显存较大的任务
```

BN中如果batch特别小的话，效果不好。如果batch大的话，反向传播梯度更稳定。但是如果太大可能会超过内存容量，跑更多的epoch，导致训练时间变长。

### 4. 梯度消失和梯度爆炸

```
1.梯度爆炸：反向传播对激活函数求导，如果导数大于1，随着网络层数的增加，梯度朝着指数爆炸的形式增加
2.梯度消失:---------------------------小于1，------------------------衰减的方式减少
3.解决方案：
	1) 使用预训练网络进行微调
	2) 使用残差结构
	3) 梯度剪切：针对梯度爆炸
	4) 激活函数使用relu，leak relu等
	5) BN
```

### 5. 过拟合和欠拟合

```
过拟合：对于训练好的的模型，若在训练集上表现好，却在测试集上表现差，这便是过拟合
欠拟合：---------------，-------------差，不必说在测试集上表现同样会差，这便是欠拟合
欠拟合解决方法：
	1) 继续训练
	2) 增加新特征
	3) 尝试非线性
	4) 如果有正则项，减小正则小参数
	5) boosting
过拟合解决方法：
	1) 数据增强
	2) 特征选择，减少特征
	3) BN
	4) 正则化如果有，增大正则项参数
	5) 交叉检验
	6) 早停(early stop)
	7) bagging
```

### 6. 正则化

L1：$\sum_i^{}|w|$     $\frac{\partial L}{\partial w_i}=sign(w_i)=\begin{cases}+1 & w_i > 0\\-1 & w_i <= 0\end{cases}$   

L2：$\frac{1}{2}\sum_i^{}w_i^2$    $\frac{\partial L}{\partial w_i}=w_i$   

L1更新公式   $w_i=w_i-\eta*1$  

L2更新公式   $w_i=w_i-\eta*w_i$  

```
正则化作用：保证模型尽可能简单，避免过拟合
L1特点：能产生等于0的值权值，剔除某些特征，模型更容易解释
L2特点：可以迅速得到比较小的权值，却难以收敛到0，产生平滑的效果，计算效率高，有解析解
L1正则是拉普拉斯先验，L2正则是高斯先验
```

### 7. 样本不均衡

```
不均衡：每个类别下的样本数目相差很大
解决方法：
	1) 扩大数据集
	2) 数据集重采样:小样本过采样，大类样本欠采样
	3) 对模型进行惩罚，增加小类样本权重，降低大类样本的权重
	4) focal loss重点关注难分负样本
```

### 8. 卷积为什么高效

```
Yann Lecun表明对于图像数据，数据的信息与结构在语义层面上都是组合性的，整体图像的语义是由局部组合而成，深度网络这种层级表征结构能依次从简单特征组合成复杂的抽象特征。
```

### 9. 全卷积网络

```
定义：没有全连接层
优点：
	1) 支持不同大小的输入，
	2) 支持端到端的训练
	3) 适合输出是图像的任务，如分割，边缘检测，光流
```

输出特征图大小计算：  $n_{out}=\lfloor\frac{n_{in}+2p-k}{s}\rfloor$   

感受野大小计算：        $l_k=l_{k-1}+[(f_k-1)*\prod_{i=1}^{k-1}s_i]$  

### 10. BP算法

BP算法全称是Back Propogation Algorithm，是一种更新权重的方法，在BP算法中，权重的更新是这样的
$$
W_l=W_l-\eta\frac{\partial{C}}{\partial{W_l}}　　其中C是损失函数，　\eta是学习率
$$
通过链式法则求出每一层的梯度，然后对每一层权值进行更新。

### 11. 小目标检测

```
小目标难检测原因：分辨率低，携带信息少
1. 放大图像做检测或者anchor更加密集
2. 多尺度融合，向FPN那种，浅层语义信息少，深层语义信息丰富，通过将深层语义信息上采样，小目标检测效果更好
3. 将IOU阈值串联筛选筛选，IOU阈值高，正样本质量高，但数量少，IOU质量低但数量多。不断提高IOU阈值可以保证样本数量的同时也能保证质量。
```

###  12. 梯度下降优化算法

1. 随机梯度下降(Stochastic Gradient Descent)
   $$
   \theta_{t+1}=\theta-\eta g_t\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad
   $$
   SGD缺点是：收敛慢，并且在鞍点处震荡，并且需要手动调节学习率

2. Momentum

   引入动量，参数更新不仅取决于当前的梯度决定，也与此前累积的下降方向有关。这使得那些梯度方向变化不大的维度可以加速更新，减少梯度方向变化较大的维度，$\gamma$ 通常取0.9。产生加速收敛和减小震荡的效果。
   $$
   \theta_{t+1}=\gamma \theta_{t-1}+\eta g_t\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad 
   $$

3. Adagrad

   对低频的参数做较大的更新，对高频的做较小的更新。减少了学习率的手动调节，学习率随着t改变
   $$
   \theta_{t+1,i}=\theta_{t,i}-\frac{\eta}{\sqrt{G_{t,ii}}+\epsilon}*g_{t,i}，其中g_{t,i}是t时刻参数\theta_i的梯度，即g_{t,i}=\triangledown_{\theta}J(\theta_i)
   $$
   Adagrad的优点是减少了学习率的手动调节，$\eta$ 一般选取0.01。

   Adagrad的缺点是分母不断积累，这样学习率就会收缩并最终会变得非常小。

4. RMSprop

   自适应学习率的方法，Adagrad会累加之前所有梯度的平方，而RMSprop仅仅计算对应的平均值，因此可缓解Adagrad算法学习率下降较快的问题
   $$
   E\left[g^2\right]_t=0.9E\left[g^2\right]_{t-1}+0.1g_t^2\\
   \theta_{t+1}=\theta_t-\frac{\eta}{\sqrt{E\left[g^2\right]_t+\epsilon}}g_t\quad \quad \eta=0.001
   $$

5. Adam

   自适应学习率的方法，同时记录了过去梯度的平方的指数衰减平均值，也记录了过去梯度的指数衰减平均值，更新时将这两者都考虑在内
   $$
   m_t=\beta_1m_{t-1}+(1-\beta_1)g_t\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad\\
   v_t=\beta_2v_{t-1}+(1-\beta|2)g_t^2\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad\\
   \theta_{t+1}=\theta_i-\frac{\eta}{\sqrt{v_t}+\epsilon}m_t\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad 
   $$

### 13. 卷积和bn合并

先卷积$x=wx+b$

再bn：
$$
\gamma\frac{(wx+b)-mean}{\sqrt{var+\epsilon}}+\beta\\
=\frac{\gamma*w}{\sqrt{var+\epsilon}}x+\gamma*\frac{b-mean}{\sqrt{var+\epsilon}}+\beta
$$
