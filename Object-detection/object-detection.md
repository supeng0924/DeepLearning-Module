# Object Detection

[toc]

## 1. 概述

主流算法分成两种：

- two stage：先通过启发式方法(selective search)或RPN产生一系列稀疏的候选框，然后对这些候选框进行分类和回归，优势是准确度高
- one stage：如yolo和ssd，其主要思路是均匀地在图片的不同的位置进行密集抽样，抽样时可以采用不同尺度和长宽比，利用CNN提取特征后直接进行分类和回归，整个过程只需一步，优势是速度快，缺点是训练困难，正负样本及其不平衡，导致准确度降低。

## 2. SSD (single shot multibox detector)

参考链接[link](https://zhuanlan.zhihu.com/p/33544892)

### 1. 综述

```
SSD采用CNN多尺度特征图并设置先验框来进行检测。对卷积层4,7,8,9,10,11输出进行预测，同时直接采用卷积来进行提取检测结果。 
```


### 2. 设计理念：  
​	1) 多尺度特征图预测：浅层语义信息少，感受野小，细节信息多用来检测小目标。深层语义信息丰富，感受野大检测大目标。  
​	2) 采用卷积进行预测：对于mxnxp大小的特征图，只需要3x3xp这样大小的卷积核得到检测结果。  
​	3) 设置先验框：借鉴Faster RCNN中anchor的理念，每个单元设置尺度和长宽比不同的先验框。不同特征图设置的先验框数目不同，尺度随着网络层数的递增逐渐减小，论文中最小取0.2，最大取0.9，通过计算可以得到各个特征图的尺度和先验框的尺度。长宽比选取{1,2,3,1/2,1/3}，根据先验框的尺度 $s_k$ 和长宽比 $a_r$ 就可以计算先验框的宽度和高度公式如下：$w^a_k=s_k\sqrt{a_r},h_k^a=s_k/\sqrt{a_r}$ ，预测的边界框 (bounding boxes)是以先验框为基准，这样减少训练的难度。每个单元每个先验框都输出一套独立的检测值，对应一个边界框，主要分为两个部分：  
​		I) 各个类别的置信度或者评分，SSD将背景也当做一个类别，如果检测C个类别，SSD需要预测C+1个置信度值.  
​		II) 边界框的位置：包含四个值(cx,cy,w,h)分别是中心坐标和宽高。是边界框相对于先验框的offset  
​			先验框用$d=(d^{cx},d^{cy},d^{w},d^{h})$ ,对应的边界框用$b=(b^{cx},b^{cy},b^w,b^h)$, 预测的Ground Truth值是这么转换的
$$
l^{cx}=(b^{cx}-d^{cx})/d^w,\quad\quad l^{cy}=(b^{cy}-d^{cy})/d^h \\
l^w=log(b^w/d^w),\quad\quad l^h=log(b^h/d^h)\\
预测时需要这个过程的反向过程进行解码
$$
  4) 对于一个mxn的特征图，共有mn个单元，每个单元设置先验框数目为 k ，那么每个单元共需要 (c+4)k 个预测值，所有单元共需要 (c+4)kmn个预测值，由于SSD采用卷积做检测，所以需要 (c+4)k个卷积核完成这个特征图的检测

### 3.训练过程

1. 先验框匹配

   匹配原则：

   ​	1) 对于每一个Ground Truth找到与其IOU最大的先验框，该先验框与其匹配

   ​	2) 与Ground Truth的IOU大于0.5，认为匹配：如果多个Ground Truth与先验框IOU大于阈值，那么先验框至于IOU最大的进行匹配

   同时为了保证正负样本平衡SSD采用了难分负样本最小化，就是对负样本抽样，抽样是按照置信度误差(预测背景置信度越小，误差越大)进行降序排列，选取误差大的top-k作为负样本，使得正负样本比例接近 1:3

2. 损失函数

   损失函数是位置误差和置信度误差加权和
   $$
   L(x,c,l,g)=\frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc}(x,l,g))\quad \quad N是先验框的正样本数量,\alpha 设置为1\\
   L_{loc}(x,l,g)=\sum_{i\in Pos}^{N}\sum_{m\in \{cx,cy,w,h\}}x_{ij}^k smooth_{L1}(l_i^m-g_j^m)\quad \\smooth_{l1}(x)=\begin{cases}0.5x^2 & | x<1|\\|x-0.5| & otherwise\end{cases}\\
   L_{conf}(x,c)=-\sum_{i\in Pos}^{N}x_{ij}^plog(c_i^p)-\sum_{i\in Neg}log(c_i^0)\quad \quad where c_i^p=\frac{exp(c_i^p)}{\sum_p exp(c_i^p)}
   $$
   

   

3. 数据扩增

```
水平翻转
旋转角度
随机裁剪
颜色扭曲
```

## 3. Faster RCNN

### 1. 概述

```
1.首先通过CNN进行特征提取，该特征图被共享于后续的RPN和全连接
2.然后用RPN生成候选框，通过softmax判断anchor属于正类还是负类，然后利用回归修正anchors，并将候选框映射到	CNN最后一层特征图上
3.通过ROI pooling层使生成固定尺寸，送入后续全连接层
4.利用softmax计算分类损失，并再次回归边界框损失
```

### 2. 模型分析

1. anchors

   ```
   每个anchor会根据图像尺寸生成3种尺度和3种长宽比的先验框。
   对特征图通过1x1卷积可以得到一个256维的特征，将256维特征转化为2k个类别，4k个偏移量，程序从候选区域中选取了
   	128个正样本和128个负样本进行训练,
   ```

2. bounding box回归原理

   每个窗口使用思维向量(x,y,w,h)分别表示中心点坐标和宽高。有三种框：预测框，Ground Truth，原始anchors框，目标是将原始的anchor框经过映射产生的预测框尽可能接近Ground Truth。思路是首先将中心点平移，然后对长和宽度进行缩放，损失函数通过smooth l1损失

3. roi pooling

   全连接计算需要固定大小的输入，所以需要针对不同输入大小的特征图，将其固定为同样的大小。  
   首先根据尺度确定出缩放的比例，然后对特征图进行水平和竖直方向划分，对网格的每一份做max pooling.

4. 分类

   通过全连接和softmax计算每个候选区域具体类别，输出类别置信度向量。然后交叉熵计算损失。并再次回归边界框获得更加精确的检测框。

5. 训练过程

   ```
   1.先训练rpn
   2.固定rpn，训练fast rcnn
   3.训练rpn
   4.微调rpn和fast rcnn
   ```

   